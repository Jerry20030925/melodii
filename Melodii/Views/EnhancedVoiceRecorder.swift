//
//  EnhancedVoiceRecorder.swift
//  Melodii
//
//  å¢å¼ºè¯­éŸ³å½•åˆ¶å™¨ï¼šå¾®ä¿¡å¼é•¿æŒ‰å½•éŸ³ + é”®ç›˜åŠ¨ç”»è¿‡æ¸¡
//

import SwiftUI
import AVFoundation
import UIKit

// MARK: - å¢å¼ºè¯­éŸ³è¾“å…¥ç»„ä»¶
struct EnhancedVoiceInputBar: View {
    @Binding var text: String
    @Binding var showKeyboard: Bool
    let onSendText: () -> Void
    let onSendVoice: (URL, TimeInterval) -> Void
    
    // çŠ¶æ€ç®¡ç†
    @State private var inputMode: InputMode = .keyboard
    @State private var isRecording = false
    @State private var recordingStartTime: Date?
    @State private var recordingDuration: TimeInterval = 0
    @State private var recordingTimer: Timer?
    @State private var audioRecorder: AVAudioRecorder?
    @State private var recordingURL: URL?
    
    // åŠ¨ç”»çŠ¶æ€
    @State private var voiceButtonScale: CGFloat = 1.0
    @State private var recordingOffset: CGSize = .zero
    @State private var isCancelling = false
    @State private var showRecordingTip = false
    
    // é”®ç›˜çŠ¶æ€
    @FocusState private var isTextFieldFocused: Bool
    @State private var keyboardHeight: CGFloat = 0
    
    enum InputMode {
        case keyboard, voice
    }
    
    var body: some View {
        VStack(spacing: 0) {
            // å½•éŸ³æç¤ºå±‚
            if showRecordingTip {
                recordingTipView
                    .transition(.move(edge: .top).combined(with: .opacity))
            }
            
            // ä¸»è¾“å…¥åŒºåŸŸ
            HStack(spacing: 12) {
                // æ¨¡å¼åˆ‡æ¢æŒ‰é’®
                modeToggleButton
                
                // è¾“å…¥åŒºåŸŸ
                inputAreaView
                
                // å‘é€æŒ‰é’®
                if !text.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty {
                    sendButton
                        .transition(.scale.combined(with: .opacity))
                }
            }
            .padding(.horizontal, 16)
            .padding(.vertical, 8)
            .background(.ultraThinMaterial)
            .overlay(
                Rectangle()
                    .frame(height: 0.5)
                    .foregroundStyle(Color(.systemGray4)),
                alignment: .top
            )
        }
        .animation(.spring(response: 0.4, dampingFraction: 0.8), value: inputMode)
        .animation(.spring(response: 0.3, dampingFraction: 0.7), value: text.isEmpty)
        .animation(.spring(response: 0.5, dampingFraction: 0.8), value: showRecordingTip)
        .onChange(of: isTextFieldFocused) { _, newValue in
            withAnimation(.spring(response: 0.4, dampingFraction: 0.8)) {
                showKeyboard = newValue
                if newValue {
                    inputMode = .keyboard
                }
            }
        }
        .onAppear {
            setupAudioSession()
        }
    }
    
    // MARK: - æ¨¡å¼åˆ‡æ¢æŒ‰é’®
    
    private var modeToggleButton: some View {
        Button {
            withAnimation(.spring(response: 0.4, dampingFraction: 0.7)) {
                if inputMode == .keyboard {
                    // åˆ‡æ¢åˆ°è¯­éŸ³æ¨¡å¼
                    inputMode = .voice
                    isTextFieldFocused = false
                    showKeyboard = false
                } else {
                    // åˆ‡æ¢åˆ°é”®ç›˜æ¨¡å¼
                    inputMode = .keyboard
                    isTextFieldFocused = true
                }
            }
            
            UIImpactFeedbackGenerator(style: .medium).impactOccurred()
        } label: {
            ZStack {
                Circle()
                    .fill(inputMode == .keyboard ? Color(.systemGray5) : Color.blue.opacity(0.1))
                    .frame(width: 36, height: 36)
                    .overlay(
                        Circle()
                            .stroke(
                                inputMode == .voice ? Color.blue : Color.clear,
                                lineWidth: 2
                            )
                    )
                
                Image(systemName: inputMode == .keyboard ? "mic.fill" : "keyboard.fill")
                    .font(.system(size: 18, weight: .medium))
                    .foregroundStyle(inputMode == .keyboard ? .secondary : Color.blue)
                    .symbolEffect(.bounce, value: inputMode)
            }
        }
        .buttonStyle(ScaleButtonStyle(scale: 0.9))
    }
    
    // MARK: - è¾“å…¥åŒºåŸŸ
    
    private var inputAreaView: some View {
        Group {
            if inputMode == .keyboard {
                keyboardInputView
                    .transition(.asymmetric(
                        insertion: .move(edge: .leading).combined(with: .opacity),
                        removal: .move(edge: .trailing).combined(with: .opacity)
                    ))
            } else {
                voiceInputView
                    .transition(.asymmetric(
                        insertion: .move(edge: .trailing).combined(with: .opacity),
                        removal: .move(edge: .leading).combined(with: .opacity)
                    ))
            }
        }
    }
    
    private var keyboardInputView: some View {
        HStack(spacing: 8) {
            TextField("è¾“å…¥æ¶ˆæ¯...", text: $text, axis: .vertical)
                .textFieldStyle(.plain)
                .font(.body)
                .focused($isTextFieldFocused)
                .lineLimit(1...4)
                .padding(.horizontal, 16)
                .padding(.vertical, 12)
                .background(Color(.systemGray6))
                .clipShape(RoundedRectangle(cornerRadius: 20))
                .overlay(
                    RoundedRectangle(cornerRadius: 20)
                        .stroke(
                            isTextFieldFocused ? Color.blue.opacity(0.5) : Color.clear,
                            lineWidth: 1
                        )
                )
        }
    }
    
    private var voiceInputView: some View {
        Button {
            // ç©ºå®ç°ï¼Œå®é™…é€»è¾‘åœ¨æ‰‹åŠ¿ä¸­
        } label: {
            HStack {
                Spacer()
                
                HStack(spacing: 8) {
                    Image(systemName: isRecording ? "stop.circle.fill" : "mic.fill")
                        .font(.system(size: 18, weight: .semibold))
                        .foregroundStyle(isRecording ? .red : .blue)
                        .symbolEffect(.pulse, options: .repeating, value: isRecording)
                    
                    Text(isRecording ? recordingText : "æŒ‰ä½è¯´è¯")
                        .font(.body)
                        .fontWeight(.medium)
                        .foregroundStyle(isRecording ? .red : .blue)
                        .monospacedDigit()
                }
                
                Spacer()
            }
            .padding(.horizontal, 16)
            .padding(.vertical, 12)
            .background(isRecording ? Color.red.opacity(0.1) : Color.blue.opacity(0.1))
            .clipShape(RoundedRectangle(cornerRadius: 20))
            .overlay(
                RoundedRectangle(cornerRadius: 20)
                    .stroke(isRecording ? Color.red.opacity(0.5) : Color.blue.opacity(0.5), lineWidth: 1)
            )
            .scaleEffect(voiceButtonScale)
            .offset(recordingOffset)
        }
        .buttonStyle(.plain)
        .simultaneousGesture(
            DragGesture(minimumDistance: 0)
                .onChanged { value in
                    if !isRecording && abs(value.translation.width) < 10 && abs(value.translation.height) < 10 {
                        // å¼€å§‹å½•éŸ³
                        startRecording()
                    }
                    
                    if isRecording {
                        recordingOffset = value.translation
                        
                        // æ£€æŸ¥æ˜¯å¦è¦å–æ¶ˆ
                        let distance = sqrt(pow(value.translation.width, 2) + pow(value.translation.height, 2))
                        let shouldCancel = distance > 100
                        
                        if shouldCancel != isCancelling {
                            withAnimation(.spring(response: 0.3, dampingFraction: 0.7)) {
                                isCancelling = shouldCancel
                                voiceButtonScale = shouldCancel ? 0.9 : 1.1
                            }
                            
                            UIImpactFeedbackGenerator(style: .light).impactOccurred()
                        }
                    }
                }
                .onEnded { value in
                    if isRecording {
                        withAnimation(.spring(response: 0.4, dampingFraction: 0.7)) {
                            recordingOffset = .zero
                            voiceButtonScale = 1.0
                        }
                        
                        if isCancelling {
                            cancelRecording()
                        } else {
                            stopRecording()
                        }
                        
                        isCancelling = false
                    }
                }
        )
    }
    
    private var recordingText: String {
        let minutes = Int(recordingDuration) / 60
        let seconds = Int(recordingDuration) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
    
    // MARK: - å‘é€æŒ‰é’®
    
    private var sendButton: some View {
        Button {
            withAnimation(.spring(response: 0.3, dampingFraction: 0.7)) {
                onSendText()
            }
        } label: {
            ZStack {
                Circle()
                    .fill(
                        LinearGradient(
                            colors: [.blue, .blue.opacity(0.8)],
                            startPoint: .topLeading,
                            endPoint: .bottomTrailing
                        )
                    )
                    .frame(width: 36, height: 36)
                    .shadow(color: .blue.opacity(0.3), radius: 4, x: 0, y: 2)
                
                Image(systemName: "arrow.up")
                    .font(.system(size: 16, weight: .bold))
                    .foregroundStyle(.white)
            }
        }
        .buttonStyle(ScaleButtonStyle(scale: 0.9))
    }
    
    // MARK: - å½•éŸ³æç¤ºè§†å›¾
    
    private var recordingTipView: some View {
        VStack(spacing: 8) {
            if isCancelling {
                Label("æ¾å¼€æ‰‹æŒ‡å–æ¶ˆå½•éŸ³", systemImage: "xmark.circle.fill")
                    .font(.subheadline)
                    .foregroundStyle(.red)
                    .symbolEffect(.bounce, value: isCancelling)
            } else {
                HStack(spacing: 8) {
                    // å½•éŸ³åŠ¨ç”»
                    HStack(spacing: 2) {
                        ForEach(0..<5, id: \.self) { index in
                            Circle()
                                .fill(Color.red)
                                .frame(width: 4, height: 4)
                                .opacity(recordingAnimationOpacity(for: index))
                                .animation(
                                    .easeInOut(duration: 0.6)
                                        .repeatForever()
                                        .delay(Double(index) * 0.1),
                                    value: isRecording
                                )
                        }
                    }
                    
                    Text("å½•éŸ³ä¸­ \(recordingText)")
                        .font(.subheadline)
                        .fontWeight(.medium)
                        .foregroundStyle(.red)
                        .monospacedDigit()
                    
                    Text("â€¢ å‘ä¸Šæ»‘åŠ¨å–æ¶ˆ")
                        .font(.caption)
                        .foregroundStyle(.secondary)
                }
            }
        }
        .padding(.horizontal, 20)
        .padding(.vertical, 12)
        .background(.ultraThinMaterial)
        .clipShape(RoundedRectangle(cornerRadius: 16))
        .shadow(color: .black.opacity(0.1), radius: 8, x: 0, y: 4)
        .padding(.horizontal, 20)
        .padding(.bottom, 8)
    }
    
    private func recordingAnimationOpacity(for index: Int) -> Double {
        if !isRecording { return 0.3 }
        
        let phase = (Date().timeIntervalSince1970 * 2).truncatingRemainder(dividingBy: 2.0)
        let normalizedIndex = Double(index) / 4.0
        
        if abs(phase - normalizedIndex) < 0.2 {
            return 1.0
        } else {
            return 0.3
        }
    }
    
    // MARK: - å½•éŸ³é€»è¾‘
    
    private func setupAudioSession() {
        do {
            try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker])
            try AVAudioSession.sharedInstance().setActive(true)
        } catch {
            print("âŒ éŸ³é¢‘ä¼šè¯è®¾ç½®å¤±è´¥: \(error)")
        }
    }
    
    private func startRecording() {
        guard !isRecording else { return }
        
        // è¯·æ±‚éº¦å…‹é£æƒé™
        AVAudioSession.sharedInstance().requestRecordPermission { [self] allowed in
            DispatchQueue.main.async {
                if allowed {
                    performStartRecording()
                } else {
                    // æƒé™è¢«æ‹’ç»ï¼Œæ˜¾ç¤ºæç¤º
                    print("âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»")
                }
            }
        }
    }
    
    private func performStartRecording() {
        do {
            // åˆ›å»ºå½•éŸ³æ–‡ä»¶
            let fileName = "voice_\(Date().timeIntervalSince1970).m4a"
            let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
            recordingURL = documentsPath.appendingPathComponent(fileName)
            
            // å½•éŸ³è®¾ç½®
            let settings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
                AVSampleRateKey: 44100,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]
            
            // åˆ›å»ºå½•éŸ³å™¨
            if let url = recordingURL {
                audioRecorder = try AVAudioRecorder(url: url, settings: settings)
                audioRecorder?.delegate = AudioRecorderDelegate()
                audioRecorder?.isMeteringEnabled = true
                audioRecorder?.record()
                
                // æ›´æ–°çŠ¶æ€
                isRecording = true
                recordingStartTime = Date()
                recordingDuration = 0
                
                withAnimation(.spring(response: 0.4, dampingFraction: 0.7)) {
                    showRecordingTip = true
                    voiceButtonScale = 1.1
                }
                
                // å¯åŠ¨è®¡æ—¶å™¨
                recordingTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                    if let startTime = recordingStartTime {
                        recordingDuration = Date().timeIntervalSince(startTime)
                        
                        // è‡ªåŠ¨åœæ­¢å½•éŸ³ï¼ˆæœ€å¤š60ç§’ï¼‰
                        if recordingDuration >= 60 {
                            stopRecording()
                        }
                    }
                }
                
                UIImpactFeedbackGenerator(style: .medium).impactOccurred()
            }
        } catch {
            print("âŒ å½•éŸ³å¼€å§‹å¤±è´¥: \(error)")
        }
    }
    
    private func stopRecording() {
        guard isRecording, let recorder = audioRecorder, let url = recordingURL else { return }
        
        recorder.stop()
        recordingTimer?.invalidate()
        recordingTimer = nil
        
        withAnimation(.spring(response: 0.4, dampingFraction: 0.7)) {
            isRecording = false
            showRecordingTip = false
            voiceButtonScale = 1.0
        }
        
        // æ£€æŸ¥å½•éŸ³æ—¶é•¿
        if recordingDuration >= 1.0 {
            // å½•éŸ³æ—¶é•¿è¶³å¤Ÿï¼Œå‘é€
            onSendVoice(url, recordingDuration)
            UINotificationFeedbackGenerator().notificationOccurred(.success)
        } else {
            // å½•éŸ³æ—¶é•¿å¤ªçŸ­ï¼Œåˆ é™¤æ–‡ä»¶
            try? FileManager.default.removeItem(at: url)
            UINotificationFeedbackGenerator().notificationOccurred(.warning)
        }
        
        cleanup()
    }
    
    private func cancelRecording() {
        guard isRecording else { return }
        
        audioRecorder?.stop()
        recordingTimer?.invalidate()
        recordingTimer = nil
        
        withAnimation(.spring(response: 0.4, dampingFraction: 0.7)) {
            isRecording = false
            showRecordingTip = false
            voiceButtonScale = 1.0
        }
        
        // åˆ é™¤å½•éŸ³æ–‡ä»¶
        if let url = recordingURL {
            try? FileManager.default.removeItem(at: url)
        }
        
        UINotificationFeedbackGenerator().notificationOccurred(.warning)
        cleanup()
    }
    
    private func cleanup() {
        audioRecorder = nil
        recordingURL = nil
        recordingStartTime = nil
        recordingDuration = 0
    }
}

// MARK: - å¢å¼ºè¯­éŸ³æ¶ˆæ¯æ°”æ³¡
struct EnhancedVoiceMessageBubble: View {
    let voiceURL: String
    let duration: TimeInterval
    let isFromMe: Bool
    
    @State private var isPlaying = false
    @State private var currentTime: TimeInterval = 0
    @State private var audioPlayer: AVAudioPlayer?
    @State private var playbackTimer: Timer?
    @State private var waveformPhase: Double = 0
    @State private var resolvedDuration: TimeInterval?
    
    var body: some View {
        HStack(spacing: 12) {
            // æ’­æ”¾æŒ‰é’®
            Button {
                togglePlayback()
            } label: {
                ZStack {
                    Circle()
                        .fill(isFromMe ? Color.white.opacity(0.2) : Color.blue)
                        .frame(width: 40, height: 40)
                    
                    Image(systemName: isPlaying ? "pause.fill" : "play.fill")
                        .font(.system(size: 16, weight: .bold))
                        .foregroundStyle(isFromMe ? .white : .white)
                        .symbolEffect(.bounce, value: isPlaying)
                }
            }
            .buttonStyle(.plain)
            
            VStack(alignment: .leading, spacing: 6) {
                // æ³¢å½¢æ˜¾ç¤º
                HStack(spacing: 2) {
                    ForEach(0..<15, id: \.self) { index in
                        RoundedRectangle(cornerRadius: 1.5)
                            .fill(waveformColor(for: index))
                            .frame(width: 3, height: waveformHeight(for: index))
                            .animation(
                                .easeInOut(duration: 0.4)
                                    .delay(Double(index) * 0.05)
                                    .repeatCount(isPlaying ? .max : 1, autoreverses: true),
                                value: waveformPhase
                            )
                    }
                }
                .frame(height: 24)
                
                // æ—¶é—´æ˜¾ç¤º
                HStack {
                    Text(formatTime(isPlaying ? currentTime : (resolvedDuration ?? duration)))
                        .font(.caption)
                        .fontWeight(.medium)
                        .foregroundStyle(isFromMe ? .white.opacity(0.8) : .secondary)
                        .monospacedDigit()
                    
                    if isPlaying {
                        Spacer()
                        
                        Text("/ \(formatTime(resolvedDuration ?? duration))")
                            .font(.caption)
                            .foregroundStyle(isFromMe ? .white.opacity(0.6) : .secondary)
                            .monospacedDigit()
                    }
                }
            }
        }
        .padding(.horizontal, 16)
        .padding(.vertical, 12)
        .background(
            RoundedRectangle(cornerRadius: 18)
                .fill(isFromMe ? 
                    LinearGradient(colors: [.blue, .blue.opacity(0.8)], startPoint: .topLeading, endPoint: .bottomTrailing) :
                    LinearGradient(colors: [Color(.systemGray5), Color(.systemGray5)], startPoint: .topLeading, endPoint: .bottomTrailing)
                )
        )
        .onAppear {
            waveformPhase = Double.random(in: 0...1)
            if duration <= 0 { Task { await resolveDurationIfNeeded() } }
        }
        .onDisappear {
            stopPlayback()
        }
    }
    
    private func waveformColor(for index: Int) -> Color {
        let progress = duration > 0 ? currentTime / duration : 0
        let indexProgress = Double(index) / 14.0
        
        if isPlaying && indexProgress <= progress {
            return isFromMe ? .white : .blue
        } else {
            return isFromMe ? .white.opacity(0.4) : .gray.opacity(0.6)
        }
    }
    
    private func waveformHeight(for index: Int) -> CGFloat {
        let baseHeight: CGFloat = 8
        let maxHeight: CGFloat = 24
        
        // æ¨¡æ‹ŸéŸ³é¢‘æ³¢å½¢
        let waveValue = sin(Double(index) * 0.5 + waveformPhase * 2) * 0.5 + 0.5
        let playbackMultiplier = isPlaying ? 1.5 : 1.0
        
        return baseHeight + (maxHeight - baseHeight) * CGFloat(waveValue) * CGFloat(playbackMultiplier)
    }
    
    private func formatTime(_ time: TimeInterval) -> String {
        let minutes = Int(time) / 60
        let seconds = Int(time) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
    
    private func togglePlayback() {
        if isPlaying {
            stopPlayback()
        } else {
            Task { await startPlayback() }
        }
    }
    
    private func startPlayback() async {
        guard let url = URL(string: voiceURL) else { return }
        
        do {
            if url.isFileURL {
                audioPlayer = try AVAudioPlayer(contentsOf: url)
            } else {
                let (data, _) = try await URLSession.shared.data(from: url)
                audioPlayer = try AVAudioPlayer(data: data)
            }
            audioPlayer?.play()

            resolvedDuration = audioPlayer?.duration
            isPlaying = true
            currentTime = 0
            
            withAnimation(.easeInOut(duration: 0.5)) {
                waveformPhase += 1
            }
            
            // å¯åŠ¨æ’­æ”¾è®¡æ—¶å™¨
            playbackTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
                guard let player = audioPlayer else { return }
                
                currentTime = player.currentTime
                
                if !player.isPlaying {
                    stopPlayback()
                }
            }
            
            UIImpactFeedbackGenerator(style: .light).impactOccurred()
            
        } catch {
            print("âŒ è¯­éŸ³æ’­æ”¾å¤±è´¥: \(error)")
        }
    }
    
    private func stopPlayback() {
        audioPlayer?.stop()
        playbackTimer?.invalidate()
        playbackTimer = nil
        
        withAnimation(.spring(response: 0.4, dampingFraction: 0.8)) {
            isPlaying = false
            currentTime = 0
        }
    }

    private func resolveDurationIfNeeded() async {
        guard resolvedDuration == nil, let url = URL(string: voiceURL) else { return }
        do {
            if url.isFileURL {
                let player = try AVAudioPlayer(contentsOf: url)
                resolvedDuration = player.duration
            } else {
                let (data, _) = try await URLSession.shared.data(from: url)
                let player = try AVAudioPlayer(data: data)
                resolvedDuration = player.duration
            }
        } catch {
            // å¿½ç•¥è§£æé”™è¯¯ï¼Œä¿æŒé»˜è®¤æ—¶é•¿
            print("âš ï¸ è§£æè¯­éŸ³æ—¶é•¿å¤±è´¥: \(error)")
        }
    }
}

// MARK: - è¾…åŠ©ç»„ä»¶

private struct ScaleButtonStyle: ButtonStyle {
    let scale: CGFloat
    
    init(scale: CGFloat = 0.95) {
        self.scale = scale
    }
    
    func makeBody(configuration: Configuration) -> some View {
        configuration.label
            .scaleEffect(configuration.isPressed ? scale : 1.0)
            .animation(.spring(response: 0.2, dampingFraction: 0.6), value: configuration.isPressed)
    }
}

// MARK: - éŸ³é¢‘å½•åˆ¶ä»£ç†
private class AudioRecorderDelegate: NSObject, AVAudioRecorderDelegate {
    func audioRecorderDidFinishRecording(_ recorder: AVAudioRecorder, successfully flag: Bool) {
        print("ğŸ¤ å½•éŸ³å®Œæˆ: \(flag ? "æˆåŠŸ" : "å¤±è´¥")")
    }
    
    func audioRecorderEncodeErrorDidOccur(_ recorder: AVAudioRecorder, error: Error?) {
        print("âŒ å½•éŸ³ç¼–ç é”™è¯¯: \(error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
    }
}

#Preview {
    VStack {
        Spacer()
        
        EnhancedVoiceInputBar(
            text: .constant(""),
            showKeyboard: .constant(false),
            onSendText: {
                print("å‘é€æ–‡æœ¬æ¶ˆæ¯")
            },
            onSendVoice: { url, duration in
                print("å‘é€è¯­éŸ³æ¶ˆæ¯: \(url), æ—¶é•¿: \(duration)ç§’")
            }
        )
    }
    .background(Color(.systemBackground))
}